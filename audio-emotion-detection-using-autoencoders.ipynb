{"cells":[{"cell_type":"code","execution_count":73,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-10-25T06:28:18.068597Z","iopub.status.busy":"2022-10-25T06:28:18.068096Z","iopub.status.idle":"2022-10-25T06:28:31.302353Z","shell.execute_reply":"2022-10-25T06:28:31.301320Z","shell.execute_reply.started":"2022-10-25T06:28:18.068487Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import re\n","import warnings\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import librosa\n","import librosa.display\n","from sklearn.preprocessing import minmax_scale\n","import IPython.display as ipd\n","\n","plt.rcParams['figure.figsize'] = (20,8)\n","plt.rcParams['font.size'] = 16\n","sns.set_style('darkgrid')\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:28:31.304511Z","iopub.status.busy":"2022-10-25T06:28:31.304188Z","iopub.status.idle":"2022-10-25T06:28:32.134395Z","shell.execute_reply":"2022-10-25T06:28:32.133217Z","shell.execute_reply.started":"2022-10-25T06:28:31.304479Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>path</th>\n","      <th>actor</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>03-01-02-02-02-01-19.wav</td>\n","      <td>/home/agarwal.aditi/mental_health/RAVDESS-nosi...</td>\n","      <td>Actor_19</td>\n","      <td>03-01-02-02-02-01</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>03-01-05-02-01-01-19.wav</td>\n","      <td>/home/agarwal.aditi/mental_health/RAVDESS-nosi...</td>\n","      <td>Actor_19</td>\n","      <td>03-01-05-02-01-01</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>03-01-08-01-01-02-19.wav</td>\n","      <td>/home/agarwal.aditi/mental_health/RAVDESS-nosi...</td>\n","      <td>Actor_19</td>\n","      <td>03-01-08-01-01-02</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>03-01-06-02-01-01-19.wav</td>\n","      <td>/home/agarwal.aditi/mental_health/RAVDESS-nosi...</td>\n","      <td>Actor_19</td>\n","      <td>03-01-06-02-01-01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>03-01-04-01-01-01-19.wav</td>\n","      <td>/home/agarwal.aditi/mental_health/RAVDESS-nosi...</td>\n","      <td>Actor_19</td>\n","      <td>03-01-04-01-01-01</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1435</th>\n","      <td>03-01-05-02-02-01-10.wav</td>\n","      <td>/home/agarwal.aditi/mental_health/RAVDESS-nosi...</td>\n","      <td>Actor_10</td>\n","      <td>03-01-05-02-02-01</td>\n","    </tr>\n","    <tr>\n","      <th>1436</th>\n","      <td>03-01-06-02-01-02-10.wav</td>\n","      <td>/home/agarwal.aditi/mental_health/RAVDESS-nosi...</td>\n","      <td>Actor_10</td>\n","      <td>03-01-06-02-01-02</td>\n","    </tr>\n","    <tr>\n","      <th>1437</th>\n","      <td>03-01-06-01-01-02-10.wav</td>\n","      <td>/home/agarwal.aditi/mental_health/RAVDESS-nosi...</td>\n","      <td>Actor_10</td>\n","      <td>03-01-06-01-01-02</td>\n","    </tr>\n","    <tr>\n","      <th>1438</th>\n","      <td>03-01-08-02-01-01-10.wav</td>\n","      <td>/home/agarwal.aditi/mental_health/RAVDESS-nosi...</td>\n","      <td>Actor_10</td>\n","      <td>03-01-08-02-01-01</td>\n","    </tr>\n","    <tr>\n","      <th>1439</th>\n","      <td>03-01-07-02-02-01-10.wav</td>\n","      <td>/home/agarwal.aditi/mental_health/RAVDESS-nosi...</td>\n","      <td>Actor_10</td>\n","      <td>03-01-07-02-02-01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1440 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["                      filename  \\\n","0     03-01-02-02-02-01-19.wav   \n","1     03-01-05-02-01-01-19.wav   \n","2     03-01-08-01-01-02-19.wav   \n","3     03-01-06-02-01-01-19.wav   \n","4     03-01-04-01-01-01-19.wav   \n","...                        ...   \n","1435  03-01-05-02-02-01-10.wav   \n","1436  03-01-06-02-01-02-10.wav   \n","1437  03-01-06-01-01-02-10.wav   \n","1438  03-01-08-02-01-01-10.wav   \n","1439  03-01-07-02-02-01-10.wav   \n","\n","                                                   path     actor  \\\n","0     /home/agarwal.aditi/mental_health/RAVDESS-nosi...  Actor_19   \n","1     /home/agarwal.aditi/mental_health/RAVDESS-nosi...  Actor_19   \n","2     /home/agarwal.aditi/mental_health/RAVDESS-nosi...  Actor_19   \n","3     /home/agarwal.aditi/mental_health/RAVDESS-nosi...  Actor_19   \n","4     /home/agarwal.aditi/mental_health/RAVDESS-nosi...  Actor_19   \n","...                                                 ...       ...   \n","1435  /home/agarwal.aditi/mental_health/RAVDESS-nosi...  Actor_10   \n","1436  /home/agarwal.aditi/mental_health/RAVDESS-nosi...  Actor_10   \n","1437  /home/agarwal.aditi/mental_health/RAVDESS-nosi...  Actor_10   \n","1438  /home/agarwal.aditi/mental_health/RAVDESS-nosi...  Actor_10   \n","1439  /home/agarwal.aditi/mental_health/RAVDESS-nosi...  Actor_10   \n","\n","                   type  \n","0     03-01-02-02-02-01  \n","1     03-01-05-02-01-01  \n","2     03-01-08-01-01-02  \n","3     03-01-06-02-01-01  \n","4     03-01-04-01-01-01  \n","...                 ...  \n","1435  03-01-05-02-02-01  \n","1436  03-01-06-02-01-02  \n","1437  03-01-06-01-01-02  \n","1438  03-01-08-02-01-01  \n","1439  03-01-07-02-02-01  \n","\n","[1440 rows x 4 columns]"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["records = []\n","for dirname, _, filenames in os.walk('/home/agarwal.aditi/mental_health/RAVDESS-nosil'):\n","    for filename in filenames:\n","        records.append([filename, os.path.join(dirname,filename)])\n","\n","data = pd.DataFrame(records, columns=['filename','path'])\n","data['actor'] = data['path'].apply(lambda x: re.findall(\"\\w+_\\d+\",x)[0])\n","data = data[data['actor']!=\"audio_speech_actors_01\"]\n","data.reset_index(inplace=True,drop=True)\n","data['type'] = data['filename'].apply(lambda x: re.split(\"-\\d+\\.wav\",x)[0])\n","data"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:28:32.136025Z","iopub.status.busy":"2022-10-25T06:28:32.135639Z","iopub.status.idle":"2022-10-25T06:28:32.145772Z","shell.execute_reply":"2022-10-25T06:28:32.145024Z","shell.execute_reply.started":"2022-10-25T06:28:32.135990Z"},"trusted":true},"outputs":[{"data":{"text/plain":["24"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["data['actor'].nunique()"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:28:32.148513Z","iopub.status.busy":"2022-10-25T06:28:32.147895Z","iopub.status.idle":"2022-10-25T06:28:32.164061Z","shell.execute_reply":"2022-10-25T06:28:32.163012Z","shell.execute_reply.started":"2022-10-25T06:28:32.148480Z"},"trusted":true},"outputs":[{"data":{"text/plain":["actor\n","Actor_19    60\n","Actor_01    60\n","Actor_02    60\n","Actor_11    60\n","Actor_17    60\n","Actor_06    60\n","Actor_07    60\n","Actor_12    60\n","Actor_15    60\n","Actor_05    60\n","Actor_22    60\n","Actor_23    60\n","Actor_24    60\n","Actor_09    60\n","Actor_03    60\n","Actor_08    60\n","Actor_04    60\n","Actor_13    60\n","Actor_18    60\n","Actor_20    60\n","Actor_21    60\n","Actor_14    60\n","Actor_16    60\n","Actor_10    60\n","Name: count, dtype: int64"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["data['actor'].value_counts()"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["data['class'] = data['type'].apply(lambda x: x.split('-')[2])"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["data['class'] = data['class'].astype(int)"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[],"source":["data['class'] = data['class'].replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:28:32.185189Z","iopub.status.busy":"2022-10-25T06:28:32.184240Z","iopub.status.idle":"2022-10-25T06:28:32.205445Z","shell.execute_reply":"2022-10-25T06:28:32.204042Z","shell.execute_reply.started":"2022-10-25T06:28:32.185155Z"},"trusted":true},"outputs":[{"data":{"text/plain":["class\n","neutral     288\n","angry       192\n","surprise    192\n","fear        192\n","sad         192\n","disgust     192\n","happy       192\n","Name: count, dtype: int64"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["data['class'].value_counts()"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:28:32.220722Z","iopub.status.busy":"2022-10-25T06:28:32.220103Z","iopub.status.idle":"2022-10-25T06:28:32.235034Z","shell.execute_reply":"2022-10-25T06:28:32.233749Z","shell.execute_reply.started":"2022-10-25T06:28:32.220684Z"},"trusted":true},"outputs":[{"data":{"text/plain":["class\n","neutral     288\n","angry       192\n","surprise    192\n","fear        192\n","sad         192\n","disgust     192\n","happy       192\n","Name: count, dtype: int64"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["data['class'].value_counts()"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:28:32.238481Z","iopub.status.busy":"2022-10-25T06:28:32.236730Z","iopub.status.idle":"2022-10-25T06:28:32.248280Z","shell.execute_reply":"2022-10-25T06:28:32.247376Z","shell.execute_reply.started":"2022-10-25T06:28:32.238441Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:28:32.252186Z","iopub.status.busy":"2022-10-25T06:28:32.251842Z","iopub.status.idle":"2022-10-25T06:28:32.260817Z","shell.execute_reply":"2022-10-25T06:28:32.259485Z","shell.execute_reply.started":"2022-10-25T06:28:32.252156Z"},"trusted":true},"outputs":[],"source":["def feature_extraction(df, mfcc=True):\n","    features = []\n","    for i,record in tqdm(df.iterrows(),total=df.shape[0]):\n","        x , sr = librosa.load(record['path'])\n","        mean_mfcc = np.mean(librosa.feature.mfcc(y=x, sr=sr, n_mfcc=128),axis=1)\n","        mean_ms = np.mean(librosa.feature.melspectrogram(y=x, sr=sr, n_mels=128),axis=1)\n","        features.append(mean_mfcc if mfcc else mean_ms)\n","        \n","    dataf = pd.DataFrame(features)\n","    dataf['class'] = df['class']\n","    return dataf"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from tqdm import tqdm\n","\n","def egge(df, smile):\n","    features = []\n","    for i, record in tqdm(df.iterrows(), total=df.shape[0]):\n","        # Process file with OpenSMILE and get features\n","        y = smile.process_file(record['path'])\n","        \n","        # Convert features to DataFrame\n","        features_df = pd.DataFrame(y)\n","        \n","        # Add path column to features_df\n","        features_df['path'] = record['path']\n","        \n","        # Append features to the list\n","        features.append(features_df)\n","    \n","    # Concatenate all features DataFrames\n","    features_df = pd.concat(features, ignore_index=True)\n","    \n","    # Merge features_df with the original DataFrame on path\n","    merged_df = pd.merge(df, features_df, on='path', how='inner')\n","    \n","    return merged_df\n"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:28:32.262715Z","iopub.status.busy":"2022-10-25T06:28:32.262374Z","iopub.status.idle":"2022-10-25T06:28:32.287300Z","shell.execute_reply":"2022-10-25T06:28:32.285430Z","shell.execute_reply.started":"2022-10-25T06:28:32.262686Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","encoder = LabelEncoder()"]},{"cell_type":"markdown","metadata":{},"source":["## MFCC Features"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:28:32.289897Z","iopub.status.busy":"2022-10-25T06:28:32.289119Z","iopub.status.idle":"2022-10-25T06:30:31.932652Z","shell.execute_reply":"2022-10-25T06:30:31.931011Z","shell.execute_reply.started":"2022-10-25T06:28:32.289847Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:22<00:00, 63.22it/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>119</th>\n","      <th>120</th>\n","      <th>121</th>\n","      <th>122</th>\n","      <th>123</th>\n","      <th>124</th>\n","      <th>125</th>\n","      <th>126</th>\n","      <th>127</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-700.392883</td>\n","      <td>61.621437</td>\n","      <td>16.980686</td>\n","      <td>23.538042</td>\n","      <td>13.520005</td>\n","      <td>12.606575</td>\n","      <td>-0.519369</td>\n","      <td>-4.675446</td>\n","      <td>-2.516029</td>\n","      <td>6.177147</td>\n","      <td>...</td>\n","      <td>-0.273638</td>\n","      <td>-0.187049</td>\n","      <td>-0.126556</td>\n","      <td>0.236960</td>\n","      <td>-0.063746</td>\n","      <td>0.026041</td>\n","      <td>-0.001292</td>\n","      <td>-0.166774</td>\n","      <td>-0.100531</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-405.778809</td>\n","      <td>30.750469</td>\n","      <td>-20.098661</td>\n","      <td>7.260509</td>\n","      <td>-7.363235</td>\n","      <td>-10.164589</td>\n","      <td>-6.574836</td>\n","      <td>-2.539282</td>\n","      <td>-11.707138</td>\n","      <td>-4.125695</td>\n","      <td>...</td>\n","      <td>-0.072577</td>\n","      <td>0.102271</td>\n","      <td>0.307730</td>\n","      <td>0.175445</td>\n","      <td>0.151858</td>\n","      <td>0.078863</td>\n","      <td>0.224321</td>\n","      <td>-0.083782</td>\n","      <td>-0.140972</td>\n","      <td>angry</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-647.876343</td>\n","      <td>78.786400</td>\n","      <td>2.392293</td>\n","      <td>8.779393</td>\n","      <td>-0.526153</td>\n","      <td>3.914570</td>\n","      <td>-3.818168</td>\n","      <td>-10.349932</td>\n","      <td>-5.101916</td>\n","      <td>-6.318324</td>\n","      <td>...</td>\n","      <td>-0.080108</td>\n","      <td>0.151396</td>\n","      <td>0.308493</td>\n","      <td>0.228258</td>\n","      <td>0.083027</td>\n","      <td>0.396278</td>\n","      <td>0.133575</td>\n","      <td>-0.441955</td>\n","      <td>-0.137462</td>\n","      <td>surprise</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-488.198517</td>\n","      <td>42.980167</td>\n","      <td>-32.867901</td>\n","      <td>4.590630</td>\n","      <td>-4.983958</td>\n","      <td>-3.605664</td>\n","      <td>-19.530750</td>\n","      <td>-14.279503</td>\n","      <td>-13.213704</td>\n","      <td>-8.078819</td>\n","      <td>...</td>\n","      <td>-0.297318</td>\n","      <td>-0.435113</td>\n","      <td>0.169336</td>\n","      <td>0.180520</td>\n","      <td>-0.012502</td>\n","      <td>0.267775</td>\n","      <td>0.236403</td>\n","      <td>0.068696</td>\n","      <td>-0.128023</td>\n","      <td>fear</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-723.713135</td>\n","      <td>67.224693</td>\n","      <td>17.922281</td>\n","      <td>18.497843</td>\n","      <td>9.793799</td>\n","      <td>13.589759</td>\n","      <td>7.002605</td>\n","      <td>-1.639939</td>\n","      <td>-0.716900</td>\n","      <td>1.205396</td>\n","      <td>...</td>\n","      <td>-0.049022</td>\n","      <td>-0.041680</td>\n","      <td>0.134135</td>\n","      <td>-0.048266</td>\n","      <td>-0.246478</td>\n","      <td>-0.309844</td>\n","      <td>-0.205153</td>\n","      <td>-0.165778</td>\n","      <td>-0.437962</td>\n","      <td>sad</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1435</th>\n","      <td>-393.291962</td>\n","      <td>37.427639</td>\n","      <td>-14.803538</td>\n","      <td>-2.003925</td>\n","      <td>-10.825532</td>\n","      <td>-11.668422</td>\n","      <td>-8.092076</td>\n","      <td>-12.388589</td>\n","      <td>-13.540404</td>\n","      <td>-5.169627</td>\n","      <td>...</td>\n","      <td>0.192264</td>\n","      <td>-0.111088</td>\n","      <td>-0.571826</td>\n","      <td>-0.259035</td>\n","      <td>0.025157</td>\n","      <td>0.427605</td>\n","      <td>0.176654</td>\n","      <td>-0.018887</td>\n","      <td>0.042530</td>\n","      <td>angry</td>\n","    </tr>\n","    <tr>\n","      <th>1436</th>\n","      <td>-469.871094</td>\n","      <td>38.700233</td>\n","      <td>-22.003654</td>\n","      <td>2.981045</td>\n","      <td>-1.439886</td>\n","      <td>-14.886630</td>\n","      <td>-9.309187</td>\n","      <td>-17.981142</td>\n","      <td>-9.321032</td>\n","      <td>1.324526</td>\n","      <td>...</td>\n","      <td>-0.094284</td>\n","      <td>-0.640148</td>\n","      <td>-0.465010</td>\n","      <td>-0.279884</td>\n","      <td>-0.174371</td>\n","      <td>0.037860</td>\n","      <td>0.037590</td>\n","      <td>-0.137029</td>\n","      <td>0.002831</td>\n","      <td>fear</td>\n","    </tr>\n","    <tr>\n","      <th>1437</th>\n","      <td>-608.372742</td>\n","      <td>55.736412</td>\n","      <td>3.106510</td>\n","      <td>8.106892</td>\n","      <td>3.487876</td>\n","      <td>2.032688</td>\n","      <td>-5.425860</td>\n","      <td>-12.726157</td>\n","      <td>1.086332</td>\n","      <td>4.814475</td>\n","      <td>...</td>\n","      <td>-0.449617</td>\n","      <td>-0.306768</td>\n","      <td>-0.276278</td>\n","      <td>-0.413240</td>\n","      <td>-0.356383</td>\n","      <td>0.003710</td>\n","      <td>0.262689</td>\n","      <td>0.320938</td>\n","      <td>-0.397841</td>\n","      <td>fear</td>\n","    </tr>\n","    <tr>\n","      <th>1438</th>\n","      <td>-475.995331</td>\n","      <td>45.401077</td>\n","      <td>-10.204731</td>\n","      <td>1.458183</td>\n","      <td>-1.101155</td>\n","      <td>-7.637703</td>\n","      <td>-6.307356</td>\n","      <td>-12.698923</td>\n","      <td>-10.170322</td>\n","      <td>-1.432007</td>\n","      <td>...</td>\n","      <td>0.279609</td>\n","      <td>-0.182069</td>\n","      <td>-0.524051</td>\n","      <td>-0.449768</td>\n","      <td>0.085295</td>\n","      <td>0.120856</td>\n","      <td>-0.031877</td>\n","      <td>-0.045308</td>\n","      <td>0.123060</td>\n","      <td>surprise</td>\n","    </tr>\n","    <tr>\n","      <th>1439</th>\n","      <td>-489.206726</td>\n","      <td>53.997875</td>\n","      <td>-20.182741</td>\n","      <td>1.013679</td>\n","      <td>-2.256691</td>\n","      <td>-9.163010</td>\n","      <td>-11.204889</td>\n","      <td>-23.213806</td>\n","      <td>-1.514864</td>\n","      <td>-1.747111</td>\n","      <td>...</td>\n","      <td>-0.131242</td>\n","      <td>-0.266847</td>\n","      <td>-0.115495</td>\n","      <td>-0.276733</td>\n","      <td>-0.121604</td>\n","      <td>0.036468</td>\n","      <td>0.313412</td>\n","      <td>0.128407</td>\n","      <td>-0.109291</td>\n","      <td>disgust</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1440 rows Ã— 129 columns</p>\n","</div>"],"text/plain":["               0          1          2          3          4          5  \\\n","0    -700.392883  61.621437  16.980686  23.538042  13.520005  12.606575   \n","1    -405.778809  30.750469 -20.098661   7.260509  -7.363235 -10.164589   \n","2    -647.876343  78.786400   2.392293   8.779393  -0.526153   3.914570   \n","3    -488.198517  42.980167 -32.867901   4.590630  -4.983958  -3.605664   \n","4    -723.713135  67.224693  17.922281  18.497843   9.793799  13.589759   \n","...          ...        ...        ...        ...        ...        ...   \n","1435 -393.291962  37.427639 -14.803538  -2.003925 -10.825532 -11.668422   \n","1436 -469.871094  38.700233 -22.003654   2.981045  -1.439886 -14.886630   \n","1437 -608.372742  55.736412   3.106510   8.106892   3.487876   2.032688   \n","1438 -475.995331  45.401077 -10.204731   1.458183  -1.101155  -7.637703   \n","1439 -489.206726  53.997875 -20.182741   1.013679  -2.256691  -9.163010   \n","\n","              6          7          8         9  ...       119       120  \\\n","0     -0.519369  -4.675446  -2.516029  6.177147  ... -0.273638 -0.187049   \n","1     -6.574836  -2.539282 -11.707138 -4.125695  ... -0.072577  0.102271   \n","2     -3.818168 -10.349932  -5.101916 -6.318324  ... -0.080108  0.151396   \n","3    -19.530750 -14.279503 -13.213704 -8.078819  ... -0.297318 -0.435113   \n","4      7.002605  -1.639939  -0.716900  1.205396  ... -0.049022 -0.041680   \n","...         ...        ...        ...       ...  ...       ...       ...   \n","1435  -8.092076 -12.388589 -13.540404 -5.169627  ...  0.192264 -0.111088   \n","1436  -9.309187 -17.981142  -9.321032  1.324526  ... -0.094284 -0.640148   \n","1437  -5.425860 -12.726157   1.086332  4.814475  ... -0.449617 -0.306768   \n","1438  -6.307356 -12.698923 -10.170322 -1.432007  ...  0.279609 -0.182069   \n","1439 -11.204889 -23.213806  -1.514864 -1.747111  ... -0.131242 -0.266847   \n","\n","           121       122       123       124       125       126       127  \\\n","0    -0.126556  0.236960 -0.063746  0.026041 -0.001292 -0.166774 -0.100531   \n","1     0.307730  0.175445  0.151858  0.078863  0.224321 -0.083782 -0.140972   \n","2     0.308493  0.228258  0.083027  0.396278  0.133575 -0.441955 -0.137462   \n","3     0.169336  0.180520 -0.012502  0.267775  0.236403  0.068696 -0.128023   \n","4     0.134135 -0.048266 -0.246478 -0.309844 -0.205153 -0.165778 -0.437962   \n","...        ...       ...       ...       ...       ...       ...       ...   \n","1435 -0.571826 -0.259035  0.025157  0.427605  0.176654 -0.018887  0.042530   \n","1436 -0.465010 -0.279884 -0.174371  0.037860  0.037590 -0.137029  0.002831   \n","1437 -0.276278 -0.413240 -0.356383  0.003710  0.262689  0.320938 -0.397841   \n","1438 -0.524051 -0.449768  0.085295  0.120856 -0.031877 -0.045308  0.123060   \n","1439 -0.115495 -0.276733 -0.121604  0.036468  0.313412  0.128407 -0.109291   \n","\n","         class  \n","0      neutral  \n","1        angry  \n","2     surprise  \n","3         fear  \n","4          sad  \n","...        ...  \n","1435     angry  \n","1436      fear  \n","1437      fear  \n","1438  surprise  \n","1439   disgust  \n","\n","[1440 rows x 129 columns]"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["dataf = feature_extraction(data)\n","dataf"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:30:31.935252Z","iopub.status.busy":"2022-10-25T06:30:31.934556Z","iopub.status.idle":"2022-10-25T06:30:31.942246Z","shell.execute_reply":"2022-10-25T06:30:31.940917Z","shell.execute_reply.started":"2022-10-25T06:30:31.935214Z"},"trusted":true},"outputs":[],"source":["X1 = dataf.iloc[:,:-1].values\n","y1 = dataf.iloc[:,-1].values \n","y1 = encoder.fit_transform(y1)"]},{"cell_type":"markdown","metadata":{},"source":["## Mel Spectrogram Features"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:30:31.944258Z","iopub.status.busy":"2022-10-25T06:30:31.943912Z","iopub.status.idle":"2022-10-25T06:32:28.350709Z","shell.execute_reply":"2022-10-25T06:32:28.349270Z","shell.execute_reply.started":"2022-10-25T06:30:31.944229Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:20<00:00, 69.62it/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>119</th>\n","      <th>120</th>\n","      <th>121</th>\n","      <th>122</th>\n","      <th>123</th>\n","      <th>124</th>\n","      <th>125</th>\n","      <th>126</th>\n","      <th>127</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000102</td>\n","      <td>0.000132</td>\n","      <td>0.010014</td>\n","      <td>0.019777</td>\n","      <td>0.008215</td>\n","      <td>0.005997</td>\n","      <td>0.014001</td>\n","      <td>0.022000</td>\n","      <td>0.018773</td>\n","      <td>0.014248</td>\n","      <td>...</td>\n","      <td>0.000034</td>\n","      <td>0.000032</td>\n","      <td>0.000032</td>\n","      <td>0.000030</td>\n","      <td>0.000035</td>\n","      <td>0.000030</td>\n","      <td>0.000022</td>\n","      <td>0.000011</td>\n","      <td>8.128426e-07</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.204939</td>\n","      <td>0.007837</td>\n","      <td>0.001730</td>\n","      <td>0.000998</td>\n","      <td>0.003056</td>\n","      <td>0.025254</td>\n","      <td>0.064966</td>\n","      <td>0.194058</td>\n","      <td>0.554539</td>\n","      <td>0.996602</td>\n","      <td>...</td>\n","      <td>0.001925</td>\n","      <td>0.001383</td>\n","      <td>0.001222</td>\n","      <td>0.001259</td>\n","      <td>0.001649</td>\n","      <td>0.002469</td>\n","      <td>0.002813</td>\n","      <td>0.002047</td>\n","      <td>2.850048e-04</td>\n","      <td>angry</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000096</td>\n","      <td>0.000046</td>\n","      <td>0.000688</td>\n","      <td>0.003677</td>\n","      <td>0.012726</td>\n","      <td>0.015543</td>\n","      <td>0.007202</td>\n","      <td>0.007033</td>\n","      <td>0.033846</td>\n","      <td>0.030709</td>\n","      <td>...</td>\n","      <td>0.000008</td>\n","      <td>0.000007</td>\n","      <td>0.000004</td>\n","      <td>0.000005</td>\n","      <td>0.000006</td>\n","      <td>0.000006</td>\n","      <td>0.000005</td>\n","      <td>0.000003</td>\n","      <td>2.346686e-07</td>\n","      <td>surprise</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.002258</td>\n","      <td>0.000123</td>\n","      <td>0.000048</td>\n","      <td>0.000020</td>\n","      <td>0.000044</td>\n","      <td>0.000130</td>\n","      <td>0.000140</td>\n","      <td>0.000247</td>\n","      <td>0.001117</td>\n","      <td>0.038726</td>\n","      <td>...</td>\n","      <td>0.000063</td>\n","      <td>0.000084</td>\n","      <td>0.000102</td>\n","      <td>0.000085</td>\n","      <td>0.000066</td>\n","      <td>0.000097</td>\n","      <td>0.000158</td>\n","      <td>0.000103</td>\n","      <td>1.295821e-05</td>\n","      <td>fear</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000153</td>\n","      <td>0.000069</td>\n","      <td>0.003380</td>\n","      <td>0.009465</td>\n","      <td>0.013482</td>\n","      <td>0.011710</td>\n","      <td>0.003917</td>\n","      <td>0.008898</td>\n","      <td>0.018658</td>\n","      <td>0.013175</td>\n","      <td>...</td>\n","      <td>0.000003</td>\n","      <td>0.000003</td>\n","      <td>0.000004</td>\n","      <td>0.000004</td>\n","      <td>0.000004</td>\n","      <td>0.000005</td>\n","      <td>0.000005</td>\n","      <td>0.000003</td>\n","      <td>2.630177e-07</td>\n","      <td>sad</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1435</th>\n","      <td>0.000284</td>\n","      <td>0.001507</td>\n","      <td>0.002652</td>\n","      <td>0.002376</td>\n","      <td>0.005163</td>\n","      <td>0.023600</td>\n","      <td>0.112236</td>\n","      <td>0.783303</td>\n","      <td>1.664240</td>\n","      <td>0.903265</td>\n","      <td>...</td>\n","      <td>0.004059</td>\n","      <td>0.003991</td>\n","      <td>0.003797</td>\n","      <td>0.003935</td>\n","      <td>0.005029</td>\n","      <td>0.009105</td>\n","      <td>0.012693</td>\n","      <td>0.007898</td>\n","      <td>6.005071e-04</td>\n","      <td>angry</td>\n","    </tr>\n","    <tr>\n","      <th>1436</th>\n","      <td>0.000053</td>\n","      <td>0.000397</td>\n","      <td>0.000624</td>\n","      <td>0.000348</td>\n","      <td>0.000176</td>\n","      <td>0.000259</td>\n","      <td>0.000467</td>\n","      <td>0.019009</td>\n","      <td>0.237898</td>\n","      <td>0.470555</td>\n","      <td>...</td>\n","      <td>0.000711</td>\n","      <td>0.000994</td>\n","      <td>0.000961</td>\n","      <td>0.001491</td>\n","      <td>0.001013</td>\n","      <td>0.000877</td>\n","      <td>0.000794</td>\n","      <td>0.000639</td>\n","      <td>4.776130e-05</td>\n","      <td>fear</td>\n","    </tr>\n","    <tr>\n","      <th>1437</th>\n","      <td>0.000038</td>\n","      <td>0.000219</td>\n","      <td>0.000402</td>\n","      <td>0.000300</td>\n","      <td>0.000201</td>\n","      <td>0.002830</td>\n","      <td>0.074776</td>\n","      <td>0.474845</td>\n","      <td>0.427268</td>\n","      <td>0.150646</td>\n","      <td>...</td>\n","      <td>0.000267</td>\n","      <td>0.000266</td>\n","      <td>0.000126</td>\n","      <td>0.000150</td>\n","      <td>0.000108</td>\n","      <td>0.000116</td>\n","      <td>0.000103</td>\n","      <td>0.000102</td>\n","      <td>6.429320e-06</td>\n","      <td>fear</td>\n","    </tr>\n","    <tr>\n","      <th>1438</th>\n","      <td>0.000191</td>\n","      <td>0.000699</td>\n","      <td>0.000997</td>\n","      <td>0.000534</td>\n","      <td>0.000603</td>\n","      <td>0.003897</td>\n","      <td>0.119252</td>\n","      <td>1.357782</td>\n","      <td>1.612602</td>\n","      <td>2.967693</td>\n","      <td>...</td>\n","      <td>0.001158</td>\n","      <td>0.001201</td>\n","      <td>0.000961</td>\n","      <td>0.000971</td>\n","      <td>0.001176</td>\n","      <td>0.001224</td>\n","      <td>0.001078</td>\n","      <td>0.000753</td>\n","      <td>9.477753e-05</td>\n","      <td>surprise</td>\n","    </tr>\n","    <tr>\n","      <th>1439</th>\n","      <td>0.000036</td>\n","      <td>0.000087</td>\n","      <td>0.000163</td>\n","      <td>0.000161</td>\n","      <td>0.000131</td>\n","      <td>0.000216</td>\n","      <td>0.010501</td>\n","      <td>0.313032</td>\n","      <td>1.082186</td>\n","      <td>2.724328</td>\n","      <td>...</td>\n","      <td>0.000304</td>\n","      <td>0.000293</td>\n","      <td>0.000407</td>\n","      <td>0.000322</td>\n","      <td>0.000462</td>\n","      <td>0.000723</td>\n","      <td>0.001193</td>\n","      <td>0.000580</td>\n","      <td>4.899484e-05</td>\n","      <td>disgust</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1440 rows Ã— 129 columns</p>\n","</div>"],"text/plain":["             0         1         2         3         4         5         6  \\\n","0     0.000102  0.000132  0.010014  0.019777  0.008215  0.005997  0.014001   \n","1     0.204939  0.007837  0.001730  0.000998  0.003056  0.025254  0.064966   \n","2     0.000096  0.000046  0.000688  0.003677  0.012726  0.015543  0.007202   \n","3     0.002258  0.000123  0.000048  0.000020  0.000044  0.000130  0.000140   \n","4     0.000153  0.000069  0.003380  0.009465  0.013482  0.011710  0.003917   \n","...        ...       ...       ...       ...       ...       ...       ...   \n","1435  0.000284  0.001507  0.002652  0.002376  0.005163  0.023600  0.112236   \n","1436  0.000053  0.000397  0.000624  0.000348  0.000176  0.000259  0.000467   \n","1437  0.000038  0.000219  0.000402  0.000300  0.000201  0.002830  0.074776   \n","1438  0.000191  0.000699  0.000997  0.000534  0.000603  0.003897  0.119252   \n","1439  0.000036  0.000087  0.000163  0.000161  0.000131  0.000216  0.010501   \n","\n","             7         8         9  ...       119       120       121  \\\n","0     0.022000  0.018773  0.014248  ...  0.000034  0.000032  0.000032   \n","1     0.194058  0.554539  0.996602  ...  0.001925  0.001383  0.001222   \n","2     0.007033  0.033846  0.030709  ...  0.000008  0.000007  0.000004   \n","3     0.000247  0.001117  0.038726  ...  0.000063  0.000084  0.000102   \n","4     0.008898  0.018658  0.013175  ...  0.000003  0.000003  0.000004   \n","...        ...       ...       ...  ...       ...       ...       ...   \n","1435  0.783303  1.664240  0.903265  ...  0.004059  0.003991  0.003797   \n","1436  0.019009  0.237898  0.470555  ...  0.000711  0.000994  0.000961   \n","1437  0.474845  0.427268  0.150646  ...  0.000267  0.000266  0.000126   \n","1438  1.357782  1.612602  2.967693  ...  0.001158  0.001201  0.000961   \n","1439  0.313032  1.082186  2.724328  ...  0.000304  0.000293  0.000407   \n","\n","           122       123       124       125       126           127     class  \n","0     0.000030  0.000035  0.000030  0.000022  0.000011  8.128426e-07   neutral  \n","1     0.001259  0.001649  0.002469  0.002813  0.002047  2.850048e-04     angry  \n","2     0.000005  0.000006  0.000006  0.000005  0.000003  2.346686e-07  surprise  \n","3     0.000085  0.000066  0.000097  0.000158  0.000103  1.295821e-05      fear  \n","4     0.000004  0.000004  0.000005  0.000005  0.000003  2.630177e-07       sad  \n","...        ...       ...       ...       ...       ...           ...       ...  \n","1435  0.003935  0.005029  0.009105  0.012693  0.007898  6.005071e-04     angry  \n","1436  0.001491  0.001013  0.000877  0.000794  0.000639  4.776130e-05      fear  \n","1437  0.000150  0.000108  0.000116  0.000103  0.000102  6.429320e-06      fear  \n","1438  0.000971  0.001176  0.001224  0.001078  0.000753  9.477753e-05  surprise  \n","1439  0.000322  0.000462  0.000723  0.001193  0.000580  4.899484e-05   disgust  \n","\n","[1440 rows x 129 columns]"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["dataf = feature_extraction(data,mfcc=False)\n","dataf"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:32:28.353979Z","iopub.status.busy":"2022-10-25T06:32:28.352735Z","iopub.status.idle":"2022-10-25T06:32:28.360835Z","shell.execute_reply":"2022-10-25T06:32:28.359528Z","shell.execute_reply.started":"2022-10-25T06:32:28.353880Z"},"trusted":true},"outputs":[],"source":["X2 = dataf.iloc[:,:-1].values\n","y2 = dataf.iloc[:,-1].values\n","y2 = encoder.fit_transform(y2)"]},{"cell_type":"markdown","metadata":{},"source":["eGEEMaps features"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1440 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [03:18<00:00,  7.27it/s]\n"]}],"source":["from sklearn.preprocessing import StandardScaler\n","import opensmile\n","\n","smile = opensmile.Smile(\n","    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n","    feature_level=opensmile.FeatureLevel.Functionals,\n",")\n","dataf = egge(data,smile)\n","\n","dataf = dataf.fillna(0)\n","X3 = dataf[dataf.columns[5:-1]]\n","y3 = dataf['class']\n","y3 = encoder.fit_transform(y3)\n","X3 = StandardScaler().fit_transform(X3)\n"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 1/1440 [00:00<04:00,  5.97it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [03:11<00:00,  7.52it/s]\n"]}],"source":["from sklearn.preprocessing import StandardScaler\n","import opensmile\n","\n","smile = opensmile.Smile(\n","    feature_set=opensmile.FeatureSet.GeMAPSv01b,\n","    feature_level=opensmile.FeatureLevel.LowLevelDescriptors,\n",")\n","dataf = egge(data,smile)\n","\n","dataf = dataf.fillna(0)\n","X4 = dataf[dataf.columns[5:-1]]\n","y4 = dataf['class']\n","y4 = encoder.fit_transform(y4)\n","X4 = StandardScaler().fit_transform(X4)\n"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:32:28.362936Z","iopub.status.busy":"2022-10-25T06:32:28.362384Z","iopub.status.idle":"2022-10-25T06:32:28.374598Z","shell.execute_reply":"2022-10-25T06:32:28.373403Z","shell.execute_reply.started":"2022-10-25T06:32:28.362900Z"},"trusted":true},"outputs":[],"source":["def LogisticRegressionPipeline(X,y):\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n","    pipeline = Pipeline([('scaler',StandardScaler()),('LogisticRegression',LogisticRegression())])\n","    pipeline.fit(X_train,y_train)\n","    y_train_pred = pipeline.predict(X_train)\n","    y_pred = pipeline.predict(X_test)\n","    \n","    cmatrix = confusion_matrix(y_test,y_pred)\n","    \n","    print(\"Training Performance\")\n","    print(classification_report(y_train,y_train_pred))\n","    print(\"-----------------------------------------\")\n","    print(\"Test Performance\")\n","    print(classification_report(y_test,y_pred))\n","    print(\"-----------------------------------------\")\n","    \n","    cv_score = cross_val_score(pipeline,X,y,cv=5)\n","    return cv_score, cmatrix"]},{"cell_type":"markdown","metadata":{},"source":["Logistic Regression: MFCCs"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:32:28.379214Z","iopub.status.busy":"2022-10-25T06:32:28.378792Z","iopub.status.idle":"2022-10-25T06:32:28.763267Z","shell.execute_reply":"2022-10-25T06:32:28.761333Z","shell.execute_reply.started":"2022-10-25T06:32:28.379180Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Performance\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.86      0.86       154\n","           1       0.76      0.73      0.74       154\n","           2       0.80      0.76      0.78       153\n","           3       0.78      0.78      0.78       154\n","           4       0.83      0.92      0.87       230\n","           5       0.73      0.67      0.70       154\n","           6       0.74      0.75      0.74       153\n","\n","    accuracy                           0.79      1152\n","   macro avg       0.79      0.78      0.78      1152\n","weighted avg       0.79      0.79      0.79      1152\n","\n","-----------------------------------------\n","Test Performance\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.74      0.72        38\n","           1       0.50      0.47      0.49        38\n","           2       0.33      0.33      0.33        39\n","           3       0.45      0.39      0.42        38\n","           4       0.63      0.59      0.61        58\n","           5       0.32      0.34      0.33        38\n","           6       0.44      0.51      0.48        39\n","\n","    accuracy                           0.49       288\n","   macro avg       0.48      0.48      0.48       288\n","weighted avg       0.49      0.49      0.49       288\n","\n","-----------------------------------------\n"]}],"source":["scores, cmatrix = LogisticRegressionPipeline(X1,y1)"]},{"cell_type":"markdown","metadata":{},"source":["Logistic Regression: Mel Spectrogram"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T06:32:29.140639Z","iopub.status.busy":"2022-10-25T06:32:29.140281Z","iopub.status.idle":"2022-10-25T06:32:29.452188Z","shell.execute_reply":"2022-10-25T06:32:29.450537Z","shell.execute_reply.started":"2022-10-25T06:32:29.140607Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Performance\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.65      0.76       154\n","           1       0.54      0.41      0.47       153\n","           2       0.65      0.47      0.54       154\n","           3       0.67      0.39      0.49       153\n","           4       0.44      0.93      0.60       230\n","           5       0.31      0.22      0.26       154\n","           6       0.47      0.39      0.43       154\n","\n","    accuracy                           0.52      1152\n","   macro avg       0.57      0.49      0.51      1152\n","weighted avg       0.56      0.52      0.51      1152\n","\n","-----------------------------------------\n","Test Performance\n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.42      0.52        38\n","           1       0.33      0.21      0.25        39\n","           2       0.48      0.39      0.43        38\n","           3       0.31      0.26      0.28        39\n","           4       0.43      0.93      0.59        58\n","           5       0.25      0.13      0.17        38\n","           6       0.42      0.34      0.38        38\n","\n","    accuracy                           0.42       288\n","   macro avg       0.41      0.38      0.37       288\n","weighted avg       0.41      0.42      0.39       288\n","\n","-----------------------------------------\n"]}],"source":["scores, cmatrix = LogisticRegressionPipeline(X2,y2)"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Performance\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.80      0.84       153\n","           1       0.77      0.79      0.78       154\n","           2       0.79      0.78      0.78       153\n","           3       0.71      0.70      0.70       154\n","           4       0.81      0.92      0.86       230\n","           5       0.66      0.58      0.62       154\n","           6       0.80      0.81      0.80       154\n","\n","    accuracy                           0.78      1152\n","   macro avg       0.77      0.77      0.77      1152\n","weighted avg       0.78      0.78      0.77      1152\n","\n","-----------------------------------------\n","Test Performance\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.72      0.73        39\n","           1       0.60      0.66      0.62        38\n","           2       0.64      0.72      0.67        39\n","           3       0.59      0.45      0.51        38\n","           4       0.72      0.74      0.73        58\n","           5       0.46      0.45      0.45        38\n","           6       0.63      0.63      0.63        38\n","\n","    accuracy                           0.63       288\n","   macro avg       0.62      0.62      0.62       288\n","weighted avg       0.63      0.63      0.63       288\n","\n","-----------------------------------------\n"]}],"source":["scores, cmatrix = LogisticRegressionPipeline(X3,y3)"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Performance\n","              precision    recall  f1-score   support\n","\n","           0       0.36      0.25      0.29     58793\n","           1       0.22      0.10      0.14     59869\n","           2       0.27      0.12      0.16     54225\n","           3       0.22      0.08      0.11     55207\n","           4       0.26      0.88      0.40     84188\n","           5       0.17      0.03      0.05     56075\n","           6       0.25      0.06      0.09     52880\n","\n","    accuracy                           0.26    421237\n","   macro avg       0.25      0.22      0.18    421237\n","weighted avg       0.25      0.26      0.20    421237\n","\n","-----------------------------------------\n","Test Performance\n","              precision    recall  f1-score   support\n","\n","           0       0.35      0.24      0.29     14698\n","           1       0.23      0.11      0.15     14967\n","           2       0.27      0.12      0.17     13556\n","           3       0.22      0.08      0.11     13802\n","           4       0.26      0.88      0.40     21048\n","           5       0.18      0.03      0.06     14019\n","           6       0.25      0.06      0.09     13220\n","\n","    accuracy                           0.26    105310\n","   macro avg       0.25      0.22      0.18    105310\n","weighted avg       0.25      0.26      0.20    105310\n","\n","-----------------------------------------\n"]}],"source":["scores, cmatrix = LogisticRegressionPipeline(X4,y4)"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["colnames = ['feature type', ' train accuracy', 'test accuracy', 'class 0 recall']"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["metrics = pd.DataFrame(columns=colnames)"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[],"source":["metrics['feature type'] = ['mfcc','melspectrogram','eGeMAPS','GeMAPS']"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["metrics['class 0 recall'] = [74,42,72,24]"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature type</th>\n","      <th>train accuracy</th>\n","      <th>test accuracy</th>\n","      <th>class 0 recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>mfcc</td>\n","      <td>79</td>\n","      <td>49</td>\n","      <td>74</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>melspectrogram</td>\n","      <td>52</td>\n","      <td>42</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>eGeMAPS</td>\n","      <td>78</td>\n","      <td>63</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GeMAPS</td>\n","      <td>26</td>\n","      <td>26</td>\n","      <td>24</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     feature type   train accuracy  test accuracy  class 0 recall\n","0            mfcc               79             49              74\n","1  melspectrogram               52             42              42\n","2         eGeMAPS               78             63              72\n","3          GeMAPS               26             26              24"]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
